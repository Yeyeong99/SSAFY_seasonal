# -*- coding: utf-8 -*-
"""PJT#19_1347698.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z0-zvHFdqiJ74-V6loabo1BRfmXg9pB0
"""

import pandas as pd

df = pd.read_csv('./reviews.csv')

df.head()

import re

def clean_text(text):
    text = re.sub(r'<.*?>', '', text)
    text = re.sub(r'[^\w\s]', '', text)
    text.lower()
    text.strip()
    return text

df['review'] = df['review'].map(lambda x: clean_text(x))

df.head()

!pip install nltk

import nltk
nltk.download('stopwords')
nltk.download('punkt_tab')

from nltk.tokenize import word_tokenize

stop_words = set(stopwords.words('english'))

def remove_stopwords(text):
    words = word_tokenize(text)
    filtered_words = [word for word in words if word not in stop_words]
    return ' '.join(filtered_words)

df['no_stopwords'] = df['review'].apply(remove_stopwords)

df.head()

from nltk.stem import PorterStemmer

stemmer = PorterStemmer()

def stem_words(text):
    words = word_tokenize(text)
    stemmed_words = [stemmer.stem(word) for word in words]

    return ' '.join(stemmed_words)

df['stemmed_review'] = df['no_stopwords'].apply(stem_words)

df['stemmed_review']

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()

X = vectorizer.fit_transform(df['stemmed_review'])
words = vectorizer.get_feature_names_out()

tfidf_matrix = X.toarray()

result = pd.DataFrame(tfidf_matrix, columns=words)
print(result)

df['review_length'] = df['stemmed_review'].apply(lambda x: len(x.split()))

positive_reviews = df[df['sentiment'] == 'positive']['review_length']
negative_reviews = df[df['sentiment'] == 'negative']['review_length']
print("긍정 리뷰 요약")
print(positive_reviews.describe())
print("부정 리뷰 요약")
print(negative_reviews.describe())

from collections import Counter
def word_frequency(df, sentiment):
    sentiment_reviews = df[df['sentiment'] == sentiment]['stemmed_review']

    combined_text = ' '.join(sentiment_reviews)
    word_counts = Counter(combined_text.split())
    most_common_words = word_counts.most_common(10)

    return most_common_words

results = {}

for sentiment in df['sentiment'].unique():
    results[sentiment] = word_frequency(df, sentiment)

for sentiment, words in results.items():
    print("감정:", sentiment)
    for word, count in words:
        print(f"단어 {word}: 빈도수 {count}")

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 5))
sns.histplot(data=df, x="review_length", hue='sentiment', multiple='stack', bins=5)
plt.title('Text Length Group by Sentiment')
plt.xlabel('Counts of Words')
plt.ylabel('Counts of Reviews')

plt.show()